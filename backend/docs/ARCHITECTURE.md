# SentiLex AI Advocate - Multi-Agent Legal Reasoning System

## ğŸ›ï¸ Court-Admissible Legal AI for Sri Lankan Law

A professional-grade, multi-agent legal reasoning system built with LangChain that prioritizes **explainability**, **traceability**, and **court admissibility**.

---

## ğŸ¯ System Overview

### What Makes This System Court-Admissible?

1. **No Hallucinations**: Only uses legal text from MCP (Model Context Protocol) service
2. **Full Audit Trail**: Every agent interaction is logged with timestamps
3. **Explicit Validation**: Gatekeeper agent blocks unsafe outputs
4. **Deterministic Routing**: Planner uses fixed execution path
5. **No Hidden Reasoning**: Chain-of-thought is never exposed to users
6. **Citation Verification**: All legal statements must cite sources

---

## ğŸ—ï¸ Architecture

### Multi-Agent Pipeline (Option B)

```
User Query
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. PLANNER     â”‚  â†’ Determines execution path (deterministic)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. RESEARCH    â”‚  â†’ Retrieves legal sources from MCP (ONLY source)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. REASONING   â”‚  â†’ Applies law to question (cites all sources)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. VALIDATION  â”‚  â†’ Detects hallucinations, verifies citations
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
   PASS? â”€â”€â”
    â†“      â”‚
   YES    NO
    â†“      â†“
â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚SYNTHâ”‚ â”‚ REFUSAL  â”‚  â†’ If validation fails, system STOPS
â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Final Response
```

### Key Architectural Rules

âœ… **DO:**
- All agents are LangChain `Runnable` objects
- Communication flows through the planner-mediated chain
- MCP is the ONLY legal knowledge source
- Every step is logged for audit trail
- Validation can BLOCK output

âŒ **DON'T:**
- No `AgentExecutor` or autonomous agents
- No direct agent-to-agent communication
- No vector databases (MCP only)
- No external legal knowledge
- No exposed chain-of-thought

---

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ agents/                    # All agent Runnables
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ planner.py            # 1ï¸âƒ£ Routing logic only
â”‚   â”œâ”€â”€ research.py           # 2ï¸âƒ£ MCP retrieval only
â”‚   â”œâ”€â”€ reasoning.py          # 3ï¸âƒ£ Legal analysis with citations
â”‚   â”œâ”€â”€ validation.py         # 4ï¸âƒ£ Gatekeeper (hallucination detection)
â”‚   â””â”€â”€ synthesizer.py        # 5ï¸âƒ£ Presentation layer
â”‚
â”œâ”€â”€ chains/                    # Pipeline orchestration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main_chain.py         # Main RunnableSequence with branching
â”‚
â”œâ”€â”€ schemas/                   # Type-safe message schemas
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ messages.py           # Pydantic models for all data
â”‚
â”œâ”€â”€ mcp_client/               # MCP service wrapper
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ client.py             # Gateway to legal knowledge
â”‚
â”œâ”€â”€ logging/                  # Audit trail system
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ audit.py              # Court-admissible logging
â”‚
â”œâ”€â”€ app.py                    # FastAPI application
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ .env.example             # Configuration template
â””â”€â”€ README.md                # This file
```

---

## ğŸš€ Getting Started

### 1. Prerequisites

- Python 3.10+
- OpenAI API key
- MCP service running locally (see MCP setup)

### 2. Installation

```bash
# Navigate to backend directory
cd backend

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Configuration

```bash
# Copy environment template
cp .env.example .env

# Edit .env with your credentials
# Required: OPENAI_API_KEY
# Optional: MCP_HOST, MCP_PORT (if not localhost:3000)
```

### 4. Run the System

```bash
# Start the API server
python app.py

# Server will start on http://localhost:8000
# API docs: http://localhost:8000/docs
```

---

## ğŸ”§ API Usage

### Submit a Legal Query

```bash
POST /query
Content-Type: application/json

{
  "question": "What is the definition of culpable homicide under Sri Lankan law?",
  "case_context": "Optional case-specific context"
}
```

**Response (Success):**
```json
{
  "status": "success",
  "data": {
    "response": "# Legal Analysis\n\n## Analysis\n...",
    "confidence_note": "âœ… High confidence...",
    "disclaimer": "IMPORTANT LEGAL NOTICE...",
    "citations": [...]
  },
  "session_id": "20260114_153045",
  "timestamp": "2026-01-14T15:30:45.123Z"
}
```

**Response (Refusal):**
```json
{
  "status": "refused",
  "data": {
    "reason": "Cannot provide analysis due to...",
    "issues": [...],
    "suggestions": "Try rephrasing..."
  },
  "session_id": "20260114_153045",
  "timestamp": "2026-01-14T15:30:45.123Z"
}
```

### Other Endpoints

```bash
# Health check
GET /health

# Retrieve audit logs
GET /audit/{session_id}

# Export audit report
GET /export/{session_id}?format=json
GET /export/{session_id}?format=markdown

# Test endpoint
POST /test/query
```

---

## ğŸ” Agent Details

### 1ï¸âƒ£ Planner Agent

**Role:** Control flow determination only

**Input:** `UserQuery`  
**Output:** `PlannerOutput`

**Behavior:**
- Deterministic (no LLM in production mode)
- All queries follow: research â†’ reason â†’ validate â†’ synthesize
- Assigns confidence to routing decision

**Code:** [`agents/planner.py`](agents/planner.py)

---

### 2ï¸âƒ£ Research Agent

**Role:** Legal source retrieval from MCP

**Input:** `PlannerOutput`  
**Output:** `ResearchOutput`

**Behavior:**
- Calls MCP service with user query
- Returns VERBATIM legal text (no summarization)
- No reasoning or interpretation
- This is the ONLY agent that accesses legal knowledge

**Code:** [`agents/research.py`](agents/research.py)

---

### 3ï¸âƒ£ Legal Reasoning Agent

**Role:** Apply law to question using ONLY provided sources

**Input:** `ResearchOutput`  
**Output:** `ReasoningOutput`

**Behavior:**
- Uses ONLY sources from Research Agent
- Must cite every legal statement
- Must explicitly state limitations
- Must NOT invent legal content
- Reasoning chain is NOT exposed to users

**Code:** [`agents/reasoning.py`](agents/reasoning.py)

---

### 4ï¸âƒ£ Validation Agent

**Role:** Gatekeeper - detect errors and hallucinations

**Input:** `(ResearchOutput, ReasoningOutput)`  
**Output:** `ValidationOutput`

**Behavior:**
- Verifies all citations exist in sources
- Detects hallucinations (content not from MCP)
- Checks consistency and completeness
- Assigns status: `pass`, `warn`, or `fail`
- If `fail`, system STOPS and returns refusal

**Code:** [`agents/validation.py`](agents/validation.py)

---

### 5ï¸âƒ£ Synthesizer Agent

**Role:** Presentation ONLY

**Input:** `(ResearchOutput, ReasoningOutput, ValidationOutput)`  
**Output:** `SynthesizerOutput`

**Behavior:**
- Formats validated reasoning for users
- Adds citations, confidence notes, disclaimers
- NO reasoning, NO retrieval, NO decisions
- Pure presentation layer

**Code:** [`agents/synthesizer.py`](agents/synthesizer.py)

---

## ğŸ“Š Audit Logging

Every agent execution is logged with:
- Timestamp (ISO 8601)
- Agent name
- Input data (full)
- Output data (full)
- Execution time (ms)
- Additional metadata

### Log Formats

**JSONL** (append-only):
```
logs/session_20260114_153045.jsonl
```

**JSON** (exportable):
```
logs/export_20260114_153045.json
```

**Markdown** (human-readable):
```
logs/report_20260114_153045.md
```

### Accessing Logs

```python
from logging.audit import get_audit_logger

audit_logger = get_audit_logger()

# Get current session logs
logs = audit_logger.get_session_logs()

# Export as JSON
audit_logger.export_session_logs("report.json")

# Generate markdown report
audit_logger.generate_audit_report("report.md")
```

---

## ğŸ§ª Testing

### Manual Testing

```bash
# Test with sample query
curl -X POST http://localhost:8000/test/query
```

### Custom Query

```bash
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What is the penalty for culpable homicide not amounting to murder?",
    "case_context": null
  }'
```

### Unit Tests (TODO)

```bash
pytest tests/
```

---

## ğŸ” MCP Integration

### What is MCP?

Model Context Protocol (MCP) is the ONLY source of legal knowledge in this system. It serves as a local service that provides verbatim legal text.

### MCP Client

The system includes a wrapper client at [`mcp_client/client.py`](mcp_client/client.py) that:
- Queries legal sources
- Retrieves specific sections
- Verifies citations
- Checks service health

### Mock Implementation

The current implementation includes **mock MCP responses** for demonstration. In production, replace with actual MCP SDK:

```python
# In mcp_client/client.py, replace:
# def _mock_mcp_query(...) â†’ with actual SDK call
# from mcp_sdk import MCPClient as SDK
# response = SDK.query(query, max_results=max_sources)
```

---

## âš™ï¸ Configuration

### Environment Variables

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `OPENAI_API_KEY` | âœ… Yes | - | OpenAI API key for LLM agents |
| `MCP_HOST` | No | `localhost` | MCP service host |
| `MCP_PORT` | No | `3000` | MCP service port |
| `API_HOST` | No | `0.0.0.0` | API server bind address |
| `API_PORT` | No | `8000` | API server port |
| `AUDIT_LOG_DIR` | No | `logs` | Directory for audit logs |

### Model Selection

Override default models in your code:

```python
from langchain_openai import ChatOpenAI

# Custom reasoning model
reasoning_llm = ChatOpenAI(model="gpt-4o", temperature=0.0)
reasoning = create_reasoning_runnable(llm=reasoning_llm)
```

---

## ğŸ“ˆ Performance

### Expected Latencies

| Agent | Typical Time |
|-------|-------------|
| Planner | < 10ms (deterministic) |
| Research | 100-500ms (MCP query) |
| Reasoning | 2-5s (LLM analysis) |
| Validation | 1-3s (LLM verification) |
| Synthesizer | < 100ms (formatting) |
| **Total** | **3-9s** |

### Optimization Tips

1. Use `gpt-4o-mini` for planner (or skip LLM entirely)
2. Cache MCP responses for repeated queries
3. Use parallel validation checks where possible
4. Pre-warm LLM connections on startup

---

## ğŸ“ For University Submissions

This system is designed to be:

âœ… **Academically Rigorous**
- Clear separation of concerns
- Well-documented architecture
- Type-safe with Pydantic schemas
- Follows LangChain best practices

âœ… **Production-Ready**
- Complete error handling
- Audit logging
- Health checks
- API documentation

âœ… **Court-Defensible**
- No hallucinations
- Full traceability
- Citation verification
- Explicit refusal mechanism

---

## ğŸ¤ Contributing

### Code Style

- Follow PEP 8
- Use type hints
- Document all public functions
- Write docstrings for all agents

### Adding a New Agent

1. Create agent file in `agents/`
2. Implement as `Runnable`
3. Define input/output schemas in `schemas/messages.py`
4. Integrate into `chains/main_chain.py`
5. Add audit logging

---

## ğŸ“ License

See [LICENSE](../LICENSE) file.

---

## ğŸ†˜ Support

For questions or issues:
1. Check the API docs: http://localhost:8000/docs
2. Review audit logs: `GET /audit/{session_id}`
3. Check MCP health: `GET /health`

---

## ğŸ”® Future Enhancements

- [ ] Multi-language support (Sinhala, Tamil)
- [ ] Case law integration
- [ ] Precedent matching
- [ ] Advanced citation formats
- [ ] Streaming responses
- [ ] Batch query processing
- [ ] Enhanced validation rules
- [ ] Custom legal domain adapters

---

**Built with â¤ï¸ for court-admissible legal AI**
